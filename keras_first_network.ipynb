{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc2615dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from keras) (1.19.2)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.3.0-cp38-cp38-win_amd64.whl (2.8 MB)\n",
      "Collecting scipy>=0.14\n",
      "  Downloading scipy-1.7.0-cp38-cp38-win_amd64.whl (33.7 MB)\n",
      "Installing collected packages: scipy, h5py, keras\n",
      "Successfully installed h5py-3.3.0 keras-2.4.3 scipy-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f109c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.7)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rohan\\anaconda3\\envs\\yoona\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=5b2c367efecf19b9d9608a9fddf25a073d041ae32cbf99016b5488ae8b924f3a\n",
      "  Stored in directory: c:\\users\\rohan\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.3.0\n",
      "    Uninstalling h5py-3.3.0:\n",
      "      Successfully uninstalled h5py-3.3.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.32.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 requests-oauthlib-1.3.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 werkzeug-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e032f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1814eb5",
   "metadata": {},
   "source": [
    "# first neural network with keras tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d029602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65cfc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d04fe",
   "metadata": {},
   "source": [
    "# Define Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334069c",
   "metadata": {},
   "source": [
    "#Models in Keras are defined as a sequence of layers.\n",
    "\n",
    "#We create a Sequential model and add layers one at a time until we are happy with our network architecture.\n",
    "\n",
    "#The first thing to get right is to ensure the input layer has the right number of \n",
    "#input features. This can be specified when creating the first layer with the input_dim argument and setting it to 8 for the 8 input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0030e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfef138",
   "metadata": {},
   "source": [
    "#Compile Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99c12723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f5d8b",
   "metadata": {},
   "source": [
    "Fit Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f03d9",
   "metadata": {},
   "source": [
    "#Epoch: One pass through all of the rows in the training dataset.\n",
    "#Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
    "#For this problem, we will run for a small number of epochs (150) and use a relatively small batch size of 10.\n",
    "\n",
    "#These configurations can be chosen experimentally by trial and error. \n",
    "#We want to train the model enough so that it learns a good (or good enough) \n",
    "#mapping of rows of input data to the output classification. \n",
    "#The model will always have some error, but the amount of error will level out after some point for a given model configuration. This is called model convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4b01117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 2s 2ms/step - loss: 24.8284 - accuracy: 0.3217\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.1623 - accuracy: 0.4309\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7321 - accuracy: 0.5749\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7634 - accuracy: 0.6186\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.6226\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.6411\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6402\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.6434\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6485\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.6435\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6543\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.6629\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6690\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6406: 0s - loss: 0.6616 - accuracy: 0.\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.6470\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6669\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6672\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6637\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6403\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6375\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.6195\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6756\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6201\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6772\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6725\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6538\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6390\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6497\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6711\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6422\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6444\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6351\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6464\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6702\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6485\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6376\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6273\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6607\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6569\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6620\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6740\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6611\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6176\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6296\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6640\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6610\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6409\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6362\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6592\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6324\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6171\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6650\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6711\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5820\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6595\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6413\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6470\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6220\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6466\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6587\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6423\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6462\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6476\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6377: 0s - loss: 0.6503 - accuracy: 0.\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6742\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6516\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6565\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6602\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6636\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6375\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6524\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6343\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6531\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6338 - accuracy: 0.6555\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6703\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6361\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6375\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6383\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6243\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6555\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.6592\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.6486\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6441\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6516\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6339\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6489\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.6622\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6472\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6493\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6283\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6680\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6595\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6684\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6732\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6323\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6603\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6528\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6648\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6361\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6550\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6383\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6702\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6347\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6295\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6455\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6312 - accuracy: 0.6398\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6511\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.6507\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6502\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6599\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6311\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.6442\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.6679\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6321\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6441\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6274\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6469\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6455\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6557\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6494\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6392\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6656\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6362\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6258\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6483\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6541\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6444\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6418\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6237\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6493\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6822\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6694\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6614\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6293\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6402 - accuracy: 0.6517\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6664\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.6623\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6374\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6431\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6774\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.6729\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6477\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6345\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6419\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6438\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6548\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6549\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.6599\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6453\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202e5672d60>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c55f88",
   "metadata": {},
   "source": [
    "#Evaluate Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08b65717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have trained our neural network on the entire dataset and we can evaluate the performance of the network on the same dataset.\n",
    "#This will only give us an idea of how well we have modeled the dataset (e.g. train accuracy), \n",
    "#but no idea of how well the algorithm might perform on new data. \n",
    "#We have done this for simplicity, but ideally, you could separate your data into train and test datasets for training and evaluation of your model.\n",
    "#You can evaluate your model on your training dataset using the evaluate() function on your model and pass it the same input and output used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62de35b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6523\n",
      "Accuracy: 65.23\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_,accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acb26a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.23"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78.30\n",
    "75.13\n",
    "72.40\n",
    "76.43\n",
    "65.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cd1f3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.47"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy:75.78\n",
    "Accuracy:78.26\n",
    "Accuracy:76.30\n",
    "Accuracy:77.47\n",
    "Accuracy:77.47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27438145",
   "metadata": {},
   "source": [
    "#Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9e8a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can adapt the above example and use it to generate predictions on the training dataset, \n",
    "#pretending it is a new dataset we have not seen before.\n",
    "\n",
    "#Making predictions is as easy as calling the predict() function on the model. \n",
    "#We are using a sigmoid activation function on the output layer, \n",
    "#so the predictions will be a probability in the range between 0 and 1. \n",
    "#We can easily convert them into a crisp binary prediction for this classification task by rounding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "066d73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "895cbe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] ----- 0 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] ----- 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] ----- 0 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] ----- 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] ----- 0 (expected 1)\n",
      "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] ----- 0 (expected 0)\n",
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] ----- 0 (expected 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] ----- 0 (expected 0)\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] ----- 0 (expected 1)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.232, 54.0] ----- 0 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%s ----- %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
